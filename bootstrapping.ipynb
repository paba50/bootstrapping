{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise demonstrate how boostrapping is performed. I am using python for the bootstrapping demo\n",
    "\n",
    "#Bootstrap method\n",
    "\n",
    "The bootstrap method is a statistical technique for estimating quantities about a population by averaging estimates from multiple small data samples. Data samples are derived by drawing a subset of data from the observations and returning it back to the observations before retrieving the next subset of samples. This process is known as sampling with replacement. \n",
    "\n",
    "The bootstrap method can be used to estimate a quantity of a population. This is done by repeatedly taking small samples, calculating the statistic, and taking the average of the calculated statistics.\n",
    "\n",
    "Bootstrapping can be used to estimate the skill of a machine learning model. This is done by training the model on the sample and evaluating the skill of the model on those samples not included in the training sample. These samples not included in a given sample are called the out-of-bag samples, or OOB for short.\n",
    "Here is this process:\n",
    "\n",
    "1. Choose a number of bootstrap samples to perform\n",
    "2. Choose a sample size\n",
    "3. For each bootstrap sample\n",
    "     3.1 Draw a sample with replacement with the chosen size\n",
    "     3.2 Fit a model on the data sample\n",
    "     3.3 Estimate the skill of the model on the out-of-bag sample.\n",
    "4. Calculate the mean of the sample of model skill estimates.\n",
    "\n",
    "Importantly, any data preparation prior to fitting the model or tuning of the hyperparameter of the model must occur within the for-loop on the data sample. This is to avoid data leakage where knowledge of the test dataset is used to improve the model. This, in turn, can result in an optimistic estimate of the model skill.\n",
    "\n",
    "One nice feature of bootstrapping is that the resulting sample estimations can be represented as a Gausian distribution (most of the time). \n",
    "\n",
    "##parameters\n",
    "\n",
    "There are two types of parameters to be set in bootstrapping. \n",
    "1. sample size: amount of observations to be used in training\n",
    "2. repetitions: how many training, testing iterations to be performed. It should be large enough to derive meaningful statistics, such as mean and standard deviantion. \n",
    "\n",
    "\n",
    "##Bootstrapping with scikit-learn package\n",
    "Scikit-learn package provides an implementation to derive a single bootstrap sample of a dataset. Given below is an example. For repetitions, we need to iterate through the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Sample: [0.6, 0.4, 0.5, 0.1]\n",
      "OOB Sample: [0.2, 0.3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# data sample\n",
    "data = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "# prepare bootstrap sample\n",
    "boot = resample(data, replace=True, n_samples=4, random_state=1)\n",
    "print('Bootstrap Sample: %s' % boot)\n",
    "# out of bag observations\n",
    "oob = [x for x in data if x not in boot]\n",
    "print('OOB Sample: %s' % oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
