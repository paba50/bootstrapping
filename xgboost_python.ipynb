{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/Users/paba/Desktop/Coding/bootstrapping\")\n",
    "os.getcwd()\n",
    "dataset = loadtxt(\"data/pima-indians-diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
      " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate independent variables and the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
      "  5.000e+01]\n",
      " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "print(X[0:5,])\n",
    "print(Y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.95%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567096081588834"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy_score.roc_auc_score(y_test,y_pred)\n",
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "test_num = round(len(dataset)*0.90)\n",
    "\n",
    "data = list(range(0,len(dataset)))\n",
    "repetitions = 500\n",
    "auc_results = numpy.zeros(repetitions)\n",
    "for i in range(repetitions):\n",
    "    boot = resample(data, replace=True, n_samples=test_num, random_state=i)\n",
    "    oob = [x for x in data if x not in boot]\n",
    "    X_train = X[boot,]\n",
    "    X_test = X[oob,] \n",
    "    y_train= Y[boot] \n",
    "    y_test = Y[oob]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test,y_pred)\n",
    "    auc_results[i] = auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76953441 0.70389725 0.69865106 0.72808908 0.70803483 0.70466981\n",
      " 0.72489316 0.73013312 0.73523277 0.69037569 0.71042199 0.7196738\n",
      " 0.71747382 0.71916061 0.71905687 0.7181878  0.69553877 0.71981169\n",
      " 0.68090062 0.73770367 0.73027853 0.7080093  0.70336799 0.74229421\n",
      " 0.68907741 0.73269231 0.74451932 0.70128115 0.74646594 0.70785985\n",
      " 0.75659879 0.75017973 0.69937276 0.72516382 0.75565611 0.69064815\n",
      " 0.72564103 0.73544974 0.73867314 0.7272619  0.70180931 0.72132353\n",
      " 0.68741337 0.68147208 0.73483347 0.69799331 0.72962078 0.68955379\n",
      " 0.73591234 0.69099099 0.7111165  0.67224672 0.714      0.71659201\n",
      " 0.6900146  0.70778261 0.71536945 0.72629052 0.7779407  0.69339875\n",
      " 0.71267504 0.71246275 0.71376518 0.73796357 0.72438352 0.71299433\n",
      " 0.6972135  0.7458575  0.67544437 0.68518519 0.73458725 0.69544324\n",
      " 0.72692882 0.73015042 0.73525074 0.69178571 0.7127193  0.67926774\n",
      " 0.7297517  0.71311318 0.71130631 0.70725995 0.70169861 0.74316696\n",
      " 0.72702703 0.69703518 0.73258936 0.70041856 0.75822525 0.67935532\n",
      " 0.70745994 0.72397892 0.71640796 0.71334417 0.72079208 0.72051657\n",
      " 0.74581646 0.70878233 0.74023281 0.70571705 0.7079888  0.71676937\n",
      " 0.71441511 0.72592924 0.76273069 0.72027768 0.76282736 0.69809244\n",
      " 0.72027791 0.71945489 0.74954986 0.72584019 0.72333303 0.66068376\n",
      " 0.69136304 0.68698382 0.72106648 0.71090407 0.71560847 0.71510644\n",
      " 0.7467655  0.73107798 0.71887674 0.71101485 0.75730674 0.71355345\n",
      " 0.71773904 0.7045098  0.69213592 0.70132791 0.70687104 0.71130435\n",
      " 0.72696177 0.72072299 0.71304348 0.72037736 0.69508514 0.77239011\n",
      " 0.71453273 0.68228247 0.71436916 0.66851852 0.7194001  0.69940476\n",
      " 0.72008987 0.72276503 0.72963415 0.71744972 0.73464386 0.76156863\n",
      " 0.71014493 0.70343137 0.79086775 0.71070087 0.75917547 0.75061293\n",
      " 0.72516835 0.68400854 0.68909565 0.68382227 0.714326   0.71212121\n",
      " 0.72178516 0.6675075  0.72611059 0.68286771 0.7225     0.72545847\n",
      " 0.73287765 0.70106769 0.6892818  0.69221106 0.74687072 0.71067556\n",
      " 0.69865043 0.71799139 0.71151298 0.72320483 0.69414113 0.73429803\n",
      " 0.71593643 0.68644231 0.7496718  0.70383128 0.70823245 0.7137931\n",
      " 0.71658957 0.74407481 0.73439857 0.69979159 0.72663252 0.70682489\n",
      " 0.73924731 0.75579274 0.72636816 0.72741557 0.71173615 0.73199472\n",
      " 0.69494174 0.73302611 0.71359247 0.73862792 0.69261513 0.72857143\n",
      " 0.68927901 0.68597458 0.73626102 0.74396971 0.69875546 0.73664344\n",
      " 0.73424908 0.72934272 0.73463825 0.75678459 0.71988304 0.70280612\n",
      " 0.6982048  0.75941504 0.75739293 0.71666667 0.71765905 0.7297848\n",
      " 0.71073378 0.69757412 0.72703349 0.73319622 0.69695513 0.70535012\n",
      " 0.70705069 0.69027269 0.67847393 0.6875     0.70706522 0.73487941\n",
      " 0.69083333 0.68770265 0.74732143 0.71266317 0.71698436 0.7042565\n",
      " 0.71197674 0.70902316 0.68717277 0.66399312 0.70769231 0.68123196\n",
      " 0.6832741  0.73908106 0.76957696 0.7202475  0.67686348 0.71719457\n",
      " 0.70698674 0.73178925 0.75183714 0.66529794 0.70271739 0.69877577\n",
      " 0.69238371 0.68803571 0.70681167 0.71937357 0.71234347 0.69369914\n",
      " 0.7254717  0.72924026 0.70934466 0.7170197  0.70651455 0.71647194\n",
      " 0.68541747 0.69780502 0.64519231 0.73541171 0.71525162 0.73132736\n",
      " 0.71135531 0.74401544 0.69270255 0.74439103 0.74484622 0.75423087\n",
      " 0.71459054 0.68819777 0.74608262 0.73123832 0.74308943 0.72140756\n",
      " 0.73748186 0.66856061 0.72610837 0.73385837 0.73904487 0.69438938\n",
      " 0.68568665 0.72369346 0.72593985 0.73667917 0.68872549 0.74432977\n",
      " 0.69355757 0.69337045 0.74723803 0.73963964 0.73615077 0.73472325\n",
      " 0.70558565 0.75011905 0.74529042 0.72087917 0.69547224 0.72372984\n",
      " 0.72990291 0.72229437 0.67417062 0.75113515 0.691962   0.72247706\n",
      " 0.7202381  0.6844967  0.74875356 0.77040444 0.7483326  0.76342506\n",
      " 0.73768771 0.70364104 0.71765842 0.7169244  0.70210834 0.73787879\n",
      " 0.67658001 0.73538886 0.71748004 0.72113604 0.69159226 0.74547654\n",
      " 0.73703496 0.73153784 0.7005106  0.69443065 0.75       0.72893878\n",
      " 0.71901625 0.68399044 0.70588235 0.72108998 0.68737484 0.71463151\n",
      " 0.65225531 0.69655667 0.70529084 0.70770929 0.71218583 0.71741597\n",
      " 0.71702899 0.72140144 0.72082032 0.73324997 0.71411156 0.72938323\n",
      " 0.72048726 0.73439755 0.76931193 0.72558978 0.73921569 0.69502029\n",
      " 0.73672547 0.71890854 0.71558872 0.67477343 0.67642602 0.71211528\n",
      " 0.73094059 0.68615474 0.68869835 0.72460087 0.73479182 0.77031571\n",
      " 0.70712919 0.73335697 0.71140614 0.72426602 0.69638533 0.70935656\n",
      " 0.72598753 0.6958912  0.65913313 0.72202604 0.73099248 0.71738933\n",
      " 0.70345428 0.71506734 0.69327823 0.7077773  0.69077568 0.67779271\n",
      " 0.76545216 0.68983594 0.72395833 0.74076705 0.68685628 0.6719958\n",
      " 0.73278168 0.73807585 0.71912103 0.73398784 0.71490773 0.75374127\n",
      " 0.69180454 0.77892592 0.72295955 0.70532204 0.72324829 0.68309734\n",
      " 0.71014493 0.74068012 0.70818982 0.74913219 0.70117647 0.75517857\n",
      " 0.6927219  0.73348212 0.72669856 0.70556341 0.72983588 0.75\n",
      " 0.72723451 0.68614752 0.7165625  0.7146469  0.71559696 0.7137449\n",
      " 0.69982944 0.7370283  0.70324092 0.67889718 0.67671569 0.72428804\n",
      " 0.73677794 0.73768396 0.73658441 0.75284553 0.7040384  0.71904845\n",
      " 0.74236425 0.69579127 0.66678705 0.72668256 0.73024302 0.67482945\n",
      " 0.71807692 0.71957364 0.768529   0.72437013 0.71281749 0.77513396\n",
      " 0.69243787 0.66829467 0.69819134 0.67923207 0.6975349  0.727593\n",
      " 0.7072665  0.70370625 0.68632378 0.6997913  0.7312523  0.7471991\n",
      " 0.71204212 0.71473575 0.68507891 0.72237861 0.70754717 0.71037978\n",
      " 0.72479759 0.7401527  0.6922658  0.7494976  0.76277709 0.71131893\n",
      " 0.75697908 0.70538721 0.7091954  0.73152946 0.70355844 0.73548175\n",
      " 0.77359694 0.72410948 0.73024267 0.75240601 0.73055556 0.75584112\n",
      " 0.7038961  0.73557886 0.71062271 0.68580392 0.69945037 0.70552107\n",
      " 0.7302377  0.70285542]\n",
      "mean auc is 0.7168679329713665\n",
      "standar deviation of auc is 0.023357576643384354\n"
     ]
    }
   ],
   "source": [
    "print(auc_results)\n",
    "print(\"mean auc is {}\".format(np.mean(auc_results)) )\n",
    "print(\"standar deviation of auc is {}\".format(np.std(auc_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
